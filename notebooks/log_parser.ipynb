{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, csv, re, importlib, json, ast\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "sys.path.insert(0, \"../\")\n",
    "from helpers.parsers import split_path\n",
    "from helpers.parsers import parse_score\n",
    "from helpers.parsers import parse_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function queries dataframe with a dictionary with columns' value\n",
    "'''\n",
    "def query_df_dict(df, value_dict):\n",
    "    indices = []\n",
    "    for key, value in value_dict.items():\n",
    "        # import pdb; pdb.set_trace();  \n",
    "        if key in df.columns:\n",
    "            \n",
    "            # Core codeline: Filter the df with values in the dict one by one\n",
    "            df = df.loc[df[key] == value]\n",
    "\n",
    "    return df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function queries dataframe with a single value\n",
    "'''\n",
    "def query_df_single(df, value):\n",
    "    indices = []   \n",
    "\n",
    "    target = df.columns[0]\n",
    "    # Core codeline: Filter the df with values in the dict one by one\n",
    "    # import pdb; pdb.set_trace();\n",
    "    df = df.loc[df[target] == value]\n",
    "\n",
    "    return df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function removes columns that have same values in all rows.\n",
    "'''\n",
    "def remove_column_same_value(df):\n",
    "    unique_count = df.apply(pd.Series.nunique)\n",
    "    df = df.drop(unique_count[unique_count == 1].index, axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function parses score from log.\n",
    "metric_pattern = ['Metric mse', 'Accuracy Score']\n",
    "\n",
    "'''\n",
    "\n",
    "def parse_log_score(model, folder_path, metric_pattern):\n",
    "    df = pd.read_csv('../results/spreadsheets/{0}_parameter_mapping.csv'.format(model))\n",
    "    file_names = os.listdir(folder_path)\n",
    "    count = 1\n",
    "\n",
    "    # Remove columns that have all same values\n",
    "    df = remove_column_same_value(df)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if file_name.startswith('log'):\n",
    "            with open(folder_path + file_name, \"r\") as f:\n",
    "                line = f.readline()\n",
    "                indices = []\n",
    "                while line:\n",
    "   \n",
    "                    if line.startswith('{'):  \n",
    "                        parameter_dict = ast.literal_eval(line)\n",
    "\n",
    "                        # query the df with all values in dict\n",
    "                        indices = query_df_dict(df, parameter_dict)\n",
    "\n",
    "                    elif line.startswith('['):\n",
    "                        parameter_list = line.rstrip('\\n')\n",
    "\n",
    "                        # query the df with all values in dict\n",
    "                        indices = query_df_single(df, parameter_list)\n",
    "\n",
    "                    elif line.startswith(metric_pattern) and indices:\n",
    "                        score = parse_score(line, pattern = metric_pattern)\n",
    "                        for index in indices:\n",
    "                            df.loc[index, str(count)] = score\n",
    "\n",
    "                    line = f.readline()\n",
    "\n",
    "            count = count + 1\n",
    "            # import pdb; pdb.set_trace();       \n",
    "    df.to_csv(\"../results/spreadsheets/{0}_{1}.csv\".format(model, metric_pattern), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'xgboost123'\n",
    "folder_path = '../cloudwatch/xgboost_123/'\n",
    "parse_log_score(model, folder_path, \"Mean Absolute Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function parses metrics from log.\n",
    "metric_pattern = ['Duration','Billed Duration','Memory Size', 'Max Memory Used']\n",
    "'''\n",
    "\n",
    "def parse_log_metric(model, folder_path, metric_pattern):\n",
    "    df = pd.read_csv('../results/spreadsheets/{0}_parameter_mapping.csv'.format(model))\n",
    "    file_names = os.listdir(folder_path)\n",
    "    count = 1\n",
    "\n",
    "    # Remove columns that have all same values\n",
    "    df = remove_column_same_value(df)\n",
    "\n",
    "    for file_name in file_names:\n",
    "        if file_name.startswith('log'):\n",
    "            with open(folder_path + file_name, \"r\") as f:\n",
    "                line = f.readline()\n",
    "                indices = []\n",
    "                while line:\n",
    "                    if line.startswith('{'):\n",
    "                        parameter_dict = ast.literal_eval(line)\n",
    "\n",
    "                        # query the df with all values in dict\n",
    "                        indices = query_df(df, parameter_dict)\n",
    "\n",
    "                    elif line.startswith('['):\n",
    "                        parameter_list = line.rstrip('\\n')\n",
    "\n",
    "                        # query the df with all values in dict\n",
    "                        indices = query_df_single(df, parameter_list)\n",
    "\n",
    "                    elif line.startswith('REPORT') and indices:\n",
    "                        metrics = parse_metrics(line)\n",
    "                        for index in indices:\n",
    "                            df.loc[index, str(count)] = metrics[metric_pattern]\n",
    "\n",
    "                    line = f.readline()\n",
    "\n",
    "            count = count + 1\n",
    "            # import pdb; pdb.set_trace();       \n",
    "    df.to_csv(\"../results/spreadsheets/{0}_{1}.csv\".format(model, metric_pattern), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_log_metric('multi_regression', '../cloudwatch/multi_regression/', 'Max Memory Used')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function parses execution time from nohup.out.\n",
    "'''\n",
    "\n",
    "def parse_log_execution_time(model, file_path):\n",
    "    count = 1\n",
    "    with open(file_path, \"r\") as f:\n",
    "        line = f.readline()\n",
    "        execution_times = {}\n",
    "        while line:\n",
    "            if line.startswith('===Async Tasks end==='):\n",
    "                temp = f.readline()\n",
    "                execution_times[count] = float(temp)\n",
    "                count = count + 1\n",
    "            line = f.readline()\n",
    "            \n",
    "    with open(\"../results/spreadsheets/{0}_execution_times.csv\".format(model), \"w\") as f:\n",
    "        w = csv.DictWriter(f, execution_times.keys())\n",
    "        w.writeheader()\n",
    "        w.writerow(execution_times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_log_execution_time('multi_regression', '../cloudwatch/multi_regression/multi_regression.out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>C3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAAA</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBBB</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name  C1  C2  C3\n",
       "0  AAAA  25   2   1\n",
       "1  BBBB  25   1  10"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"Name\": [\"AAAA\", \"BBBB\"],\n",
    "        \"C1\": [25, 25],\n",
    "        \"C2\": [2, 1],\n",
    "        \"C3\": [1, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
